{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6120d7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/groups/ioannidislab/cthoma13/gptoss_bullshit_detector/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from nnsight import LanguageModel\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db437263",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"openai/gpt-oss-20b\")\n",
    "lm = LanguageModel(\n",
    "    \"openai/gpt-oss-20b\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=t.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240303ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"hij svkasdjivaijdsvaijsd ssd asdv asd vas dv a\", \n",
    "    \"how sfgsfa \", \n",
    "    \"are sjpfbwjp fbjpsdfbj opasdj bajsbapdsobpjv asp ojdbaojsdbv apjosdpo vas pdob opjasjo\", \n",
    "    \"you a sdpjo pasdjo\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d6798a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    [\n",
    "    {\"role\": \"system\", \"content\": \"Do sth avj dsjiavsja\"},\n",
    "    {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "    for user_prompt in prompts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b62e88c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_dict=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd58b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_token_id = 199999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2020ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_lens = [(input_ids != stop_token_id).sum() for input_ids in inputs[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb553060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(102), tensor(89), tensor(121), tensor(91)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7eba2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_vec = t.ones((1, 1, lm.config.hidden_size), dtype=t.bfloat16).to(lm.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "995e034b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MXFP4 quantization requires triton >= 3.4.0 and triton_kernels installed, we will default to dequantizing the model to bf16\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "ename": "NNsightError",
     "evalue": "Cannot copy out of meta tensor; no data!",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):",
      "  File \"/private/groups/ioannidislab/cthoma13/gptoss_bullshit_detector/.venv/lib/python3.13/site-packages/nnsight/tracing/graph/node.py\", line 294, in execute",
      "    args, kwargs = self.prepare_inputs((self.args, self.kwargs))",
      "                   ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/private/groups/ioannidislab/cthoma13/gptoss_bullshit_detector/.venv/lib/python3.13/site-packages/nnsight/intervention/graph/node.py\", line 81, in prepare_inputs",
      "    inputs = util.apply(inputs, _to, torch.Tensor, inplace=not fake)",
      "  File \"/private/groups/ioannidislab/cthoma13/gptoss_bullshit_detector/.venv/lib/python3.13/site-packages/nnsight/util.py\", line 44, in apply",
      "    return tuple([apply(_data, fn, cls, inplace=inplace) for _data in data])",
      "                  ~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/private/groups/ioannidislab/cthoma13/gptoss_bullshit_detector/.venv/lib/python3.13/site-packages/nnsight/util.py\", line 39, in apply",
      "    data[idx] = apply(_data, fn, cls, inplace=inplace)",
      "                ~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/private/groups/ioannidislab/cthoma13/gptoss_bullshit_detector/.venv/lib/python3.13/site-packages/nnsight/util.py\", line 32, in apply",
      "    return fn(data)",
      "  File \"/private/groups/ioannidislab/cthoma13/gptoss_bullshit_detector/.venv/lib/python3.13/site-packages/nnsight/intervention/graph/node.py\", line 79, in _to",
      "    return value.to(device)",
      "           ~~~~~~~~^^^^^^^^",
      "NotImplementedError: Cannot copy out of meta tensor; no data!",
      "",
      "During handling of the above exception, another exception occurred:",
      "",
      "Traceback (most recent call last):",
      "  File \"/data/tmp/ipykernel_735939/1977487835.py\", line 4, in <module>",
      "    steered = h - 1.0 * steering_vec                                        # <-- no in-place; broadcasting ok",
      "",
      "NNsightError: Cannot copy out of meta tensor; no data!"
     ]
    }
   ],
   "source": [
    "with lm.generate(inputs, max_new_tokens=4096):\n",
    "    with lm.model.layers.all():\n",
    "        h = lm.model.layers[0].output[0]                                 # <-- select hidden-state slot\n",
    "        steered = h - 1.0 * steering_vec                                        # <-- no in-place; broadcasting ok\n",
    "        lm.model.layers[0].output[0] = steered\n",
    "    generated_ids = lm.generator.output.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad4f54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 2880])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bullshit",
   "language": "python",
   "name": "bullshit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
